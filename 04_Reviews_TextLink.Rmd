---
title: "Hotel Reviews"
author: "Torrey Capobianco"
date: "5/8/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries

```{r warning = FALSE}
library(dplyr)
library(tidyr)
library(tidytext)
library(stringr)
library(igraph)
library(ggraph)
library(plotly)
```

## Data

```{r}
df <- read.csv('data/hotel_text_cln.csv')

head(df)
```

```{r}
# separate positive, negative scores and all scores

positive <- df$cln_full_sentence[df$score == "positive"]
negative <- df$cln_full_sentence[df$score == "negative"]
all <- df$cln_full_sentence


# convert positive/negative to tibble
pos <- tibble(line = 1:20737, text = positive)

neg <- tibble(line = 1:2849, text = negative)

all <- tibble(line= 1:31670, text = all)

```


## Positive Reviews

### Frequent Single Words
```{r}
pos_tokens <- pos %>% 
  unnest_tokens(word, text)


data(stop_words)

pos_tokens <- pos_tokens %>%
  anti_join(stop_words, by =c("word" = "word"))

pos_tokens %>%
  count(word, sort=TRUE)
```



### BiGrams
```{r}
# get 2 word combo

pos_bigram <- pos %>%
  unnest_tokens(bigram, text, token = "ngrams", n=2)

pos_bigram
```

### Most common n-grams
```{r}
pos_bigram %>%
  count(bigram, sort = TRUE)
```

```{r}
# separate into two columns
pos_bigrams_separated <- pos_bigram %>%
  separate(bigram, c("word1", "word2"), sep=" ")

# new bigram counts:
pos_bigram_counts <- pos_bigrams_separated %>%
  count(word1, word2, sort = TRUE)

pos_bigram_counts
```
```{r}
pos_bigrams_separated %>%
  filter(word1 == "nice") %>%
  count(word1, word2, sort=TRUE)
```
```{r}
pos_bigrams_separated %>%
  filter(word1 == "need") %>%
  count(word1, word2, sort=TRUE)
```
```{r}
pos_bigrams_separated %>%
  filter(word1 == "area") %>%
  count(word1, word2, sort=TRUE)
```

```{r}
pos_bigrams_separated %>%
  filter(word1 == "room") %>%
  count(word1, word2, sort=TRUE)
```

```{r}
pos_bigrams_separated %>%
  filter(word1 == "love") %>%
  count(word1, word2, sort=TRUE)
```


### TriGrams

```{r}

pos_trigram <- pos %>%
  unnest_tokens(bigram, text, token = "ngrams", n=3)

pos_trigram
```

### Most common tri-grams
```{r}
pos_trigram %>%
  count(bigram, sort = TRUE)
```

```{r}
# separate into two columns
pos_trigrams_separated <- pos_trigram %>%
  separate(bigram, c("word1", "word2", "word3"), sep=" ")

# new trigram counts:
pos_trigram_counts <- pos_trigrams_separated %>%
  count(word1, word2, word3, sort = TRUE)

pos_trigram_counts
```
```{r}
pos_trigrams_separated %>%
  filter(word1 == "need") %>%
  count(word1, word2, word3, sort=TRUE)
```


### Graph Network

```{r}
# filter for only relatively common combinations
pos_bigram_graph <- pos_bigram_counts %>%
  filter(n > 115) %>%
  graph_from_data_frame()

set.seed(2017)

ggsave("graphs/positive_network.png", width = 15, height = 10, dpi = 300)

ggraph(pos_bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha=n, edge_width=n), 
                 end_cap=circle(.07, 'inches')) +
  geom_node_point(color='#44749D', size=2) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1, size=4) + 
 labs(title="Word Network of Positive Reviews")
```

## Negative Reviews

### Frequent Single Words
```{r}
neg_tokens <- neg %>% 
  unnest_tokens(word, text)


data(stop_words)

neg_tokens <- neg_tokens %>%
  anti_join(stop_words, by =c("word" = "word"))

neg_tokens %>%
  count(word, sort=TRUE)
```



### BiGrams
```{r}
neg_bigram <- neg %>%
  unnest_tokens(bigram, text, token = "ngrams", n=2)

neg_bigram
```

### Most common n-grams
```{r}
neg_bigram %>%
  count(bigram, sort = TRUE)
```

```{r}
# separate into two columns
neg_bigrams_separated <- neg_bigram %>%
  separate(bigram, c("word1", "word2"), sep=" ")

# new bigram counts:
neg_bigram_counts <- neg_bigrams_separated %>%
  count(word1, word2, sort = TRUE)

neg_bigram_counts
```
```{r}
neg_bigrams_separated %>%
  filter(word1 == "check") %>%
  count(word1, word2, sort=TRUE)
```
```{r}
neg_bigrams_separated %>%
  filter(word1 == "go") %>%
  count(word1, word2, sort=TRUE)
```
```{r}
neg_bigrams_separated %>%
  filter(word1 == "one") %>%
  count(word1, word2, sort=TRUE)
```

```{r}
neg_bigrams_separated %>%
  filter(word1 == "room") %>%
  count(word1, word2, sort=TRUE)
```

```{r}
pos_bigrams_separated %>%
  filter(word1 == "bad") %>%
  count(word1, word2, sort=TRUE)
```
### TriGrams

```{r}

neg_trigram <- neg %>%
  unnest_tokens(bigram, text, token = "ngrams", n=3)

neg_trigram
```

### Most common tri-grams
```{r}
neg_trigram %>%
  count(bigram, sort = TRUE)
```

```{r}
# separate into two columns
neg_trigrams_separated <- neg_trigram %>%
  separate(bigram, c("word1", "word2", "word3"), sep=" ")

# new bigram counts:
neg_trigram_counts <- neg_trigrams_separated %>%
  count(word1, word2, word3, sort = TRUE)

neg_trigram_counts
```
```{r}
neg_trigrams_separated %>%
  filter(word1 == "go") %>%
  count(word1, word2, word3, sort=TRUE)
```

```{r}
neg_trigrams_separated %>%
  filter(word1 == "room") %>%
  count(word1, word2, word3, sort=TRUE)
```

```{r}
neg_trigrams_separated %>%
  filter(word1 == "check", word2 == "room") %>%
  count(word1, word2, word3, sort=TRUE)
```

```{r}
neg_trigrams_separated %>%
  filter(word1 == "room", word2 == "key") %>%
  count(word1, word2, word3, sort=TRUE)
``` 


### Graph Network

```{r}
# filter for only relatively common combinations
neg_bigram_graph <- neg_bigram_counts %>%
  filter(n > 30) %>%
  graph_from_data_frame()

neg_bigram_graph
```

```{r}
set.seed(2017)

a <- grid::arrow(type = "closed", length = unit(.15, "inches"))

ggsave("graphs/negative_network.png", width = 15, height = 10, dpi = 300)

ggraph(neg_bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha=n, edge_width=n), 
                 end_cap=circle(.07, 'inches')) +
  geom_node_point(color='#44749D', size=2) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1, size=5) + 
 labs(title="Word Network of Negative Reviews")
```

## All Reviews

```{r}
all_tokens <- all %>% 
  unnest_tokens(word, text)


data(stop_words)

all_tokens <- all_tokens %>%
  anti_join(stop_words, by =c("word" = "word"))

```



### BiGrams
```{r}
all_bigram <- all %>%
  unnest_tokens(bigram, text, token = "ngrams", n=2)

all_bigram
```

### Most common n-grams
```{r}
all_bigram %>%
  count(bigram, sort = TRUE)
```

```{r}
# separate into two columns
all_bigrams_separated <- all_bigram %>%
  separate(bigram, c("word1", "word2"), sep=" ")

# new bigram counts:
all_bigram_counts <- all_bigrams_separated %>%
  count(word1, word2, sort = TRUE)

all_bigram_counts
```

```{r}
# filter for only relatively common combinations
all_bigram_graph <- all_bigram_counts %>%
  filter(n > 250) %>%
  graph_from_data_frame()

set.seed(2017)

a <- grid::arrow(type = "closed", length = unit(.15, "inches"))

ggsave("graphs/network_all_250.png", width = 15, height = 10, dpi = 300)

ggraph(all_bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha=n, edge_width=n), 
                 end_cap=circle(.07, 'inches')) +
  geom_node_point(color='#44749D', size=2) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1, size=5) + 
 labs(title="Word Network of all Reviews: Frequency of 250 or Greater")
```

```{r}
# filter for only relatively common combinations
all_bigram_graph <- all_bigram_counts %>%
  filter(n > 150) %>%
  graph_from_data_frame()

set.seed(2017)

a <- grid::arrow(type = "closed", length = unit(.15, "inches"))

ggsave("graphs/network_all_150.png", width = 15, height = 10, dpi = 300)

ggraph(all_bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha=n, edge_width=n), 
                 end_cap=circle(.07, 'inches')) +
  geom_node_point(color='#44749D', size=2) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1, size=5) + 
 labs(title="Word Network of all Reviews: Frequency of 150 or Greater")
```

```{r}
# filter for only relatively common combinations
all_bigram_graph <- all_bigram_counts %>%
  filter(n > 200) %>%
  graph_from_data_frame()

set.seed(2017)


ggsave("graphs/network_all_200.png", width = 15, height = 10, dpi = 300)

ggraph(all_bigram_graph, layout = "fr") +
  geom_edge_link(aes(edge_alpha=n, edge_width=n), 
                 end_cap=circle(.07, 'inches')) +
  geom_node_point(color='#44749D', size=2) +
  geom_node_text(aes(label = name), vjust = 1.5, hjust = 1, size=4) + 
 labs(title="Word Network of all Reviews: Frequency of 200 or Greater")
```